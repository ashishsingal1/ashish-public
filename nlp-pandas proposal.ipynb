{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nlp-pandas\n",
    "Thoughts on a data analytics add on that can answer questions on custom datasets using NLP (or even just structuring without intelligence at first.\n",
    "\n",
    "The idea is to complement / replace data viz platforms like Tableau -- instead of users having to generate the tables they want, they should be able to ask free form questions.\n",
    "\n",
    "The original idea was nlp-sql, but I think nlp-pandas may work better to start out with. pandas has a lot of built in functionality that may come in handy.\n",
    "\n",
    "## Sample of how it could work\n",
    "\n",
    " - users_table = ['id', 'f_name', 'l_name', 'city', 'state']\n",
    " - orders_table = ['id', 'user_id', 'order_date', 'payment_method']\n",
    " - items_table = ['id', 'product_id', 'order_id', 'count']\n",
    " - products_table = ['id', 'name', 'price']\n",
    "\n",
    "### Questions:\n",
    "\n",
    " - Number of orders placed in the last six months\n",
    " - Bar chart of orders placed in the last six months by month\n",
    " - Number of orders placed in the last six months by state\n",
    " - Top 10 orders by value\n",
    " - Top 10 states by revenue\n",
    " - Top 10 products by revenue this month\n",
    " - Top 10 products by revenue by month for the last six months\n",
    " \n",
    "We would have to understand how we can translate this to SQL. Perhaps we can use pandas first for now. We'd have to calculate intermediate fields. We'd also have to understand table linkages. Perhaps to start, we can denormalize tables and just run the queries on single tables. Later, we can start to break these out.\n",
    "\n",
    "Changing name to `nlp-pandas`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-12T10:52:31.105851",
     "start_time": "2017-01-12T10:52:31.104851"
    }
   },
   "source": [
    "### Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import nlp-pandas as nd\n",
    "import pandas as pd\n",
    "\n",
    "df_users, df_orders, df_items, df_products\n",
    "\n",
    "ds = nd.Dataset(df_users, df_orders, df_items, df_products) # set the dataset\n",
    "df_answer = ds.ask('Top 10 products by revenue by month for the last six months')\n",
    "```\n",
    "\n",
    "df_answer is the result of the last line. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we get it working?\n",
    "\n",
    "The first way is to hard code stuff in. This is how Alexa works. For example, if we see 'top' or 'largest' or 'biggest' followed by a number, we know to sort desc and limit the number. If we see 'by' followed by this, we know what column to sort using.\n",
    "\n",
    "It is easiest to first work on a single table. Later, it might be possible to join tables intelligently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
